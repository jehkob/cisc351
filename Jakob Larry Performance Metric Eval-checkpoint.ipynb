{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title:  Credit Card Fraud Detection\n",
    "\n",
    "# Author: Jakob Larry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "The goal in this project is to compare multiple machine learning classifiers, namely Logistic Regression, Random Forest (typical bagging method), XGBoost on a popular predictive data analystics task, Credit Card Fraud Detection. \n",
    "\n",
    "\n",
    "## Dataset\n",
    "The dataset we are using is from Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud#creditcard.csv. The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets  # import build-in dataset\n",
    "from sklearn import svm  # import model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score # for cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  load dataset and set up pipeline.\n",
    "In reality, we usually use 10-fold cross validation rather than reporting evalution performance on one single split of data. \n",
    "\n",
    "``` \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_idx, test_idx, in cv.split(X, y):\n",
    "   sm = SMOTE()\n",
    "   X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train)\n",
    "   model = ...  # Choose a model here\n",
    "   model.fit(X_train_oversampled, y_train_oversampled ) \n",
    "   y_pred = model.predict(X_test)\n",
    "   print(f'For fold {fold}:')\n",
    "   print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "   print(f'f-score: {f1_score(y_test, y_pred)}') \n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of normal transacation is 99.82725143693798\n",
      "percentage of fraud transacation 0.1727485630620034\n",
      "[0.99824438 0.99578652 0.99596208 0.99683989 0.99806882]\n",
      "Accuracy: 1.00 (+/- 0.00)\n",
      "Time: 13.47\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Jakob/Downloads/creditcard.csv\")\n",
    "data.head(3)\n",
    "data.isnull().sum().max()\n",
    "\n",
    "Count_Normal_transacation = len(data[data[\"Class\"]==0]) # normal transaction are repersented by 0\n",
    "Count_Fraud_transacation = len(data[data[\"Class\"]==1]) # fraud by 1\n",
    "Percentage_of_Normal_transacation = Count_Normal_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of normal transacation is\",Percentage_of_Normal_transacation*100)\n",
    "Percentage_of_Fraud_transacation= Count_Fraud_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of fraud transacation\",Percentage_of_Fraud_transacation*100)\n",
    "\n",
    "def data_prepration(x): \n",
    "    x_features= x.ix[:,x.columns != \"Class\"]\n",
    "    x_labels=x.ix[:,x.columns==\"Class\"]\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,test_size=0.3)\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)\n",
    "data.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n",
    "data.head()\n",
    "\n",
    "data = data[0:len(data)//10]\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "#creating target and feature sets\n",
    "y = data.iloc[:, data.columns == 'Class']\n",
    "X = data.iloc[:, data.columns != 'Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "start_time = time.time()\n",
    "clf_svc_cv = svm.SVC(kernel='linear',C=1)  # build a support vector machine with parameters\n",
    "scores_clf_svc_cv = cross_val_score(clf_svc_cv,X,y.values.ravel(),cv=5)  # 5-fold cross validation\n",
    "print(scores_clf_svc_cv) # print results\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_clf_svc_cv.mean(), scores_clf_svc_cv.std() * 2))  # print accuracy\n",
    "print(\"Time: %0.2f\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  model building and evaluation. \n",
    "Create three models: Logistic Regression, Random Forest, Gradient Boost (XGBoost) using their default hyperparameter values. Report the default parameter values and model performance in terms of precision, recall, F-measure, and AUC.\n",
    "\n",
    "Note that Fraud is the positive class. We don't need to consider all hyperparameters provided by the tool, only focusing on three or four important ones. \n",
    "\n",
    "We will apply SMOTE technique to deal with the highly imbalanced dataset. Ref. https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1:\n",
      "Accuracy: 0.9912219101123596\n",
      "f-score: 0.3902439024390244\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 0.25\n",
      "AUC: 0.9079488082658212\n",
      "Time: 3.67\n",
      "\n",
      "\n",
      "For fold 2:\n",
      "Accuracy: 0.983497191011236\n",
      "f-score: 0.27692307692307694\n",
      "Recall: 1.0\n",
      "Precision: 0.16071428571428573\n",
      "AUC: 0.9998434503541935\n",
      "Time: 7.07\n",
      "\n",
      "\n",
      "For fold 3:\n",
      "Accuracy: 0.9747191011235955\n",
      "f-score: 0.1818181818181818\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 0.10126582278481013\n",
      "AUC: 0.923603772846464\n",
      "Time: 10.41\n",
      "\n",
      "\n",
      "For fold 4:\n",
      "Accuracy: 0.9561095505617978\n",
      "f-score: 0.12587412587412586\n",
      "Recall: 1.0\n",
      "Precision: 0.06716417910447761\n",
      "AUC: 0.9992172517709679\n",
      "Time: 14.20\n",
      "\n",
      "\n",
      "For fold 5:\n",
      "Accuracy: 0.9873595505617978\n",
      "f-score: 0.2173913043478261\n",
      "Recall: 0.5555555555555556\n",
      "Precision: 0.13513513513513514\n",
      "AUC: 0.8862275449101796\n",
      "Time: 17.72\n",
      "\n",
      "\n",
      "For fold 6:\n",
      "Accuracy: 0.9792837078651685\n",
      "f-score: 0.23376623376623376\n",
      "Recall: 1.0\n",
      "Precision: 0.1323529411764706\n",
      "AUC: 1.0\n",
      "Time: 21.97\n",
      "\n",
      "\n",
      "For fold 7:\n",
      "Accuracy: 0.9845505617977528\n",
      "f-score: 0.2903225806451613\n",
      "Recall: 1.0\n",
      "Precision: 0.16981132075471697\n",
      "AUC: 0.9980039920159681\n",
      "Time: 25.41\n",
      "\n",
      "\n",
      "For fold 8:\n",
      "Accuracy: 0.9877106741573034\n",
      "f-score: 0.3636363636363636\n",
      "Recall: 1.0\n",
      "Precision: 0.2222222222222222\n",
      "AUC: 1.0\n",
      "Time: 28.66\n",
      "\n",
      "\n",
      "For fold 9:\n",
      "Accuracy: 0.983497191011236\n",
      "f-score: 0.25396825396825395\n",
      "Recall: 0.8\n",
      "Precision: 0.1509433962264151\n",
      "AUC: 0.9919309372797745\n",
      "Time: 32.23\n",
      "\n",
      "\n",
      "For fold 10:\n",
      "Accuracy: 0.9933286516853933\n",
      "f-score: 0.3870967741935483\n",
      "Recall: 0.6\n",
      "Precision: 0.2857142857142857\n",
      "AUC: 0.8928470754052149\n",
      "Time: 36.54\n",
      "\n",
      "\n",
      "AvgAccuracy: 0.982127808988764\n",
      "Avgf-score: 0.2721040797611796\n",
      "AvgRecall: 0.8733333333333333\n",
      "AvgPrecision: 0.1675323588832819\n",
      "AvgAUC: 0.9599622832848583\n",
      "Total Time: 36.54\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "sum_accuracy = 0\n",
    "sum_F1 = 0\n",
    "sum_recall = 0\n",
    "sum_precision = 0\n",
    "sum_AUC = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X.iloc[train_idx, :], y.iloc[train_idx, 0])\n",
    "    #default parameters\n",
    "    model = sklearn.linear_model.LogisticRegression(max_iter=750)\n",
    "    model.fit(X_train_oversampled, y_train_oversampled ) \n",
    "    y_pred = model.predict(X.iloc[test_idx, :])\n",
    "\n",
    "    #Calculate accuracy\n",
    "    accuracy = model.score(X.iloc[test_idx, :], y.iloc[test_idx, :])\n",
    "    #Calculate precision\n",
    "    precision = precision_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate recall\n",
    "    recall = recall_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate f-measure\n",
    "    F1 = f1_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate AUC\n",
    "    AUC = roc_auc_score(y.iloc[test_idx, :], model.predict_proba(X.iloc[test_idx,:])[:,1])\n",
    "    \n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    sum_accuracy += accuracy\n",
    "    print(f'f-score: {F1}') \n",
    "    sum_F1 += F1\n",
    "    print(f'Recall: {recall}') \n",
    "    sum_recall += recall\n",
    "    print(f'Precision: {precision}') \n",
    "    sum_precision += precision\n",
    "    print(f'AUC: {AUC}')\n",
    "    sum_AUC += AUC\n",
    "    print(\"Time: %0.2f\" % (time.time() - start_time))\n",
    "    fold+=1\n",
    "    print('\\n')\n",
    "\n",
    "print(f'AvgAccuracy: {sum_accuracy/10}')\n",
    "print(f'Avgf-score: {sum_F1/10}') \n",
    "print(f'AvgRecall: {sum_recall/10}') \n",
    "print(f'AvgPrecision: {sum_precision/10}') \n",
    "print(f'AvgAUC: {sum_AUC/10}') \n",
    "print(\"Total Time: %0.2f\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1:\n",
      "Accuracy: 0.9992977528089888\n",
      "f-score: 0.8750000000000001\n",
      "Recall: 0.7777777777777778\n",
      "Precision: 1.0\n",
      "AUC: 0.9998043129427419\n",
      "Time: 51.97\n",
      "\n",
      "\n",
      "For fold 2:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "AUC: 0.9998434503541935\n",
      "Time: 110.43\n",
      "\n",
      "\n",
      "For fold 3:\n",
      "Accuracy: 0.9996488764044944\n",
      "f-score: 0.9411764705882353\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 1.0\n",
      "AUC: 0.9989824273022583\n",
      "Time: 176.52\n",
      "\n",
      "\n",
      "For fold 4:\n",
      "Accuracy: 0.9985955056179775\n",
      "f-score: 0.8181818181818181\n",
      "Recall: 1.0\n",
      "Precision: 0.6923076923076923\n",
      "AUC: 0.9992563891824194\n",
      "Time: 238.52\n",
      "\n",
      "\n",
      "For fold 5:\n",
      "Accuracy: 0.9936797752808989\n",
      "f-score: 0.4\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 0.2857142857142857\n",
      "AUC: 0.9927595788814527\n",
      "Time: 305.17\n",
      "\n",
      "\n",
      "For fold 6:\n",
      "Accuracy: 0.9982443820224719\n",
      "f-score: 0.782608695652174\n",
      "Recall: 1.0\n",
      "Precision: 0.6428571428571429\n",
      "AUC: 1.0\n",
      "Time: 370.60\n",
      "\n",
      "\n",
      "For fold 7:\n",
      "Accuracy: 0.9957865168539326\n",
      "f-score: 0.4545454545454546\n",
      "Recall: 0.5555555555555556\n",
      "Precision: 0.38461538461538464\n",
      "AUC: 0.9980431294274197\n",
      "Time: 428.45\n",
      "\n",
      "\n",
      "For fold 8:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "AUC: 1.0\n",
      "Time: 496.85\n",
      "\n",
      "\n",
      "For fold 9:\n",
      "Accuracy: 0.9978932584269663\n",
      "f-score: 0.5714285714285715\n",
      "Recall: 0.4\n",
      "Precision: 1.0\n",
      "AUC: 0.9996124031007751\n",
      "Time: 559.78\n",
      "\n",
      "\n",
      "For fold 10:\n",
      "Accuracy: 0.9985955056179775\n",
      "f-score: 0.7499999999999999\n",
      "Recall: 0.6\n",
      "Precision: 1.0\n",
      "AUC: 0.8928470754052149\n",
      "Time: 619.49\n",
      "\n",
      "\n",
      "AvgAccuracy: 0.9981741573033709\n",
      "Avgf-score: 0.7592941010396255\n",
      "AvgRecall: 0.7888888888888889\n",
      "AvgPrecision: 0.8005494505494507\n",
      "AvgAUC: 0.9881148766596475\n",
      "Total Time: 619.49\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "fold = 1\n",
    "sum_accuracy = 0\n",
    "sum_F1 = 0\n",
    "sum_recall = 0\n",
    "sum_precision = 0\n",
    "sum_AUC = 0\n",
    "start_time = time.time()\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X.iloc[train_idx, :], y.iloc[train_idx, 0])\n",
    "    #default parameters\n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(X_train_oversampled, y_train_oversampled )\n",
    "    y_pred = random_forest.predict(X.iloc[test_idx, :])\n",
    "\n",
    "    #Calculate accuracy\n",
    "    accuracy = random_forest.score(X.iloc[test_idx, :], y.iloc[test_idx, :])\n",
    "    #Calculate precision\n",
    "    precision = precision_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate recall\n",
    "    recall = recall_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate f-measure\n",
    "    F1 = f1_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate AUC\n",
    "    AUC = roc_auc_score(y.iloc[test_idx, :], model.predict_proba(X.iloc[test_idx,:])[:,1])\n",
    "    \n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    sum_accuracy += accuracy\n",
    "    print(f'f-score: {F1}') \n",
    "    sum_F1 += F1\n",
    "    print(f'Recall: {recall}') \n",
    "    sum_recall += recall\n",
    "    print(f'Precision: {precision}') \n",
    "    sum_precision += precision\n",
    "    print(f'AUC: {AUC}')\n",
    "    sum_AUC += AUC\n",
    "    print(\"Time: %0.2f\" % (time.time() - start_time))\n",
    "    fold+=1\n",
    "    print('\\n')\n",
    "\n",
    "print(f'AvgAccuracy: {sum_accuracy/10}')\n",
    "print(f'Avgf-score: {sum_F1/10}') \n",
    "print(f'AvgRecall: {sum_recall/10}') \n",
    "print(f'AvgPrecision: {sum_precision/10}')\n",
    "print(f'AvgAUC: {sum_AUC/10}') \n",
    "print(\"Total Time: %0.2f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1:\n",
      "Accuracy: 0.9989466292134831\n",
      "f-score: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 1.0\n",
      "AUC: 0.9998043129427419\n",
      "Time: 11.18\n",
      "\n",
      "\n",
      "For fold 2:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "AUC: 0.9998434503541935\n",
      "Time: 25.22\n",
      "\n",
      "\n",
      "For fold 3:\n",
      "Accuracy: 0.9996488764044944\n",
      "f-score: 0.9411764705882353\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 1.0\n",
      "AUC: 0.9989824273022583\n",
      "Time: 35.95\n",
      "\n",
      "\n",
      "For fold 4:\n",
      "Accuracy: 0.9971910112359551\n",
      "f-score: 0.6923076923076924\n",
      "Recall: 1.0\n",
      "Precision: 0.5294117647058824\n",
      "AUC: 0.9992563891824194\n",
      "Time: 47.14\n",
      "\n",
      "\n",
      "For fold 5:\n",
      "Accuracy: 0.9989466292134831\n",
      "f-score: 0.8421052631578948\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 0.8\n",
      "AUC: 0.9927595788814527\n",
      "Time: 57.49\n",
      "\n",
      "\n",
      "For fold 6:\n",
      "Accuracy: 0.9982443820224719\n",
      "f-score: 0.782608695652174\n",
      "Recall: 1.0\n",
      "Precision: 0.6428571428571429\n",
      "AUC: 1.0\n",
      "Time: 67.48\n",
      "\n",
      "\n",
      "For fold 7:\n",
      "Accuracy: 0.9975421348314607\n",
      "f-score: 0.5882352941176471\n",
      "Recall: 0.5555555555555556\n",
      "Precision: 0.625\n",
      "AUC: 0.9980431294274197\n",
      "Time: 78.35\n",
      "\n",
      "\n",
      "For fold 8:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n",
      "AUC: 1.0\n",
      "Time: 89.95\n",
      "\n",
      "\n",
      "For fold 9:\n",
      "Accuracy: 0.9989466292134831\n",
      "f-score: 0.8235294117647058\n",
      "Recall: 0.7\n",
      "Precision: 1.0\n",
      "AUC: 0.9996124031007751\n",
      "Time: 100.65\n",
      "\n",
      "\n",
      "For fold 10:\n",
      "Accuracy: 0.9989466292134831\n",
      "f-score: 0.8235294117647058\n",
      "Recall: 0.7\n",
      "Precision: 1.0\n",
      "AUC: 0.8928470754052149\n",
      "Time: 111.72\n",
      "\n",
      "\n",
      "AvgAccuracy: 0.9988412921348315\n",
      "Avgf-score: 0.8293492239353055\n",
      "AvgRecall: 0.8400000000000001\n",
      "AvgPrecision: 0.8597268907563025\n",
      "AvgAUC: 0.9881148766596475\n",
      "Total Time: 111.72\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost (XGBoost)\n",
    "\n",
    "fold = 1\n",
    "sum_accuracy = 0\n",
    "sum_F1 = 0\n",
    "sum_recall = 0\n",
    "sum_precision = 0\n",
    "sum_AUC = 0\n",
    "start_time = time.time()\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X.iloc[train_idx, :], y.iloc[train_idx, 0])\n",
    "    #default parameters\n",
    "    gbm = xgb.XGBClassifier().fit(X_train_oversampled, y_train_oversampled)\n",
    "    y_pred = gbm.predict(X.iloc[test_idx, :])\n",
    "\n",
    "\n",
    "    #Calculate accuracy\n",
    "    accuracy = gbm.score(X.iloc[test_idx, :], y.iloc[test_idx, :])\n",
    "    #Calculate precision\n",
    "    precision = precision_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate recall\n",
    "    recall = recall_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate f-measure\n",
    "    F1 = f1_score(y.iloc[test_idx, :], y_pred)\n",
    "    #Calculate AUC\n",
    "    AUC = roc_auc_score(y.iloc[test_idx, :], model.predict_proba(X.iloc[test_idx,:])[:,1])\n",
    "    \n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    sum_accuracy += accuracy\n",
    "    print(f'f-score: {F1}') \n",
    "    sum_F1 += F1\n",
    "    print(f'Recall: {recall}') \n",
    "    sum_recall += recall\n",
    "    print(f'Precision: {precision}') \n",
    "    sum_precision += precision\n",
    "    print(f'AUC: {AUC}')\n",
    "    sum_AUC += AUC\n",
    "    print(\"Time: %0.2f\" % (time.time() - start_time))\n",
    "    fold+=1\n",
    "    print('\\n')\n",
    "\n",
    "print(f'AvgAccuracy: {sum_accuracy/10}')\n",
    "print(f'Avgf-score: {sum_F1/10}') \n",
    "print(f'AvgRecall: {sum_recall/10}') \n",
    "print(f'AvgPrecision: {sum_precision/10}') \n",
    "print(f'AvgAUC: {sum_AUC/10}') \n",
    "print(\"Total Time: %0.2f\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes our results from the experiment.\n",
    "\n",
    "| Classifier | Default Hyperparameter values| Precision | Recall | AUC |\n",
    "| Logistic Regression |  tol=0.0001, C=1.0, penalty='l2' |0.1675323588832819 | 0.8733333333333333 | 0.9599622832848583 |\n",
    "| Random Forest | n_estimators=100, min_samples_split=2, min_samples_leaf=1 | 0.8005494505494507 |  0.7888888888888889 |  0.9881148766596475 |\n",
    "| XGBoost| gamma=0, learningrate=0.2, max_depth=6 | 0.8597268907563025 |0.8400000000000001 | 0.9881148766596475 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   hyperparameter tuning.\n",
    "For each classifier, turn the hyperparameter using random search and grid search. Report the best performance for each classifier and their running time.\n",
    "Ref. https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "1.0 {'tol': 0.01, 'penalty': 'l2', 'C': 10}\n",
      "36.96621513366699\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "#creating target and feature sets\n",
    "y = data.iloc[:, data.columns == 'Class']\n",
    "X = data.iloc[:, data.columns != 'Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "X_train_oversampled, y_train_oversampled = sm.fit_sample(X_train, y_train.values.flatten())\n",
    "\n",
    "penalty = ['l1','l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "tol = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "\n",
    "\n",
    "param_grid = {'penalty': penalty,\n",
    "               'C': C,\n",
    "               'tol': tol,\n",
    "               }\n",
    "\n",
    "start_time = time.time()\n",
    "model = sklearn.linear_model.LogisticRegression(max_iter=750)\n",
    "rand = RandomizedSearchCV(model, param_distributions=param_grid, cv=10, n_jobs=-1)\n",
    "rand_result = rand.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(\"Logistic Regression\")\n",
    "print(rand_result.best_score_, rand_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 {'C': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "166.44900941848755\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Grid Search\n",
    "start_time = time.time()\n",
    "model = sklearn.linear_model.LogisticRegression(max_iter=750)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 10, n_jobs = -1)\n",
    "grid_result = grid.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(grid_result.best_score_, grid_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "n_estimators = [5, 10, 25, 50, 100, 175, 250]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [1, 2, 3, 4, 5, 7, 10]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [1, 2, 5, 10]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 {'n_estimators': 25, 'min_samples_split': 2, 'max_features': 'auto', 'max_depth': None}\n",
      "280.44327116012573\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Random Search\n",
    "start_time = time.time()\n",
    "model = RandomForestClassifier()\n",
    "rand = RandomizedSearchCV(model, param_distributions=param_grid, cv=10, n_jobs=-1)\n",
    "rand_result = rand.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(rand_result.best_score_, rand_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 {'max_depth': 4, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 250}\n",
      "11421.238187074661\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Grid Search\n",
    "start_time = time.time()\n",
    "model = RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 10, n_jobs = -1)\n",
    "grid_result = grid.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(grid_result.best_score_, grid_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "learning_rate = [0.01,0.05, 0.10, 0.15, 0.20, 0.25, 0.30,0.5]\n",
    "max_dept =  [3, 4, 5, 6, 8, 10, 25]\n",
    "n_estimators  = [10, 50, 100, 150, 200]\n",
    "param_grid = {\"learning_rate\"    : learning_rate,\n",
    " \"max_depth\": max_dept,\n",
    " \"n_estimators\" :  n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Random Search\n",
    "start_time = time.time()\n",
    "model = xgb.XGBClassifier()\n",
    "rand = RandomizedSearchCV(model, param_distributions=param_grid, cv=10, n_jobs=-1)\n",
    "rand_result = rand.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(rand_result.best_score_, rand_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e86755b7d47a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_train_oversampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_oversampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    729\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             )\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "#XGB Grid Search\n",
    "start_time = time.time()\n",
    "model = xgb.XGBClassifier()\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv=10,  n_jobs = -1) \n",
    "grid_result = grid.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(grid_result.best_score_, grid_result.best_params_)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jakob\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " time 0.09707093238830566\n",
      "Logistic Regression by Grid Search: accuracy 1.0, precision 0.0, recall 0.0, f-score 0.0, AUC 0.8928470754052149\n",
      "\n",
      " time 0.09375548362731934\n",
      "Logistic Regression by Random Search: accuracy 1.0, precision 0.0, recall 0.0, f-score 0.0, AUC 0.8928470754052149\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8bbbd7064056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mrandom_forest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_oversampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_oversampled\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#Calculate accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1760\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2065\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2067\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2068\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many indexers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2007\u001b[0m             \u001b[1;31m# check that the key does not exceed the maximum size of the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2008\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2009\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Can only index by location with a [{self._valid_types}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "#Logit Grid Search {'C': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
    "start_time = time.time()\n",
    "model = sklearn.linear_model.LogisticRegression(C=1, penalty='l2', tol=1e-05, max_iter=750)\n",
    "model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "F1 = f1_score(y_test, y_pred)\n",
    "try:\n",
    "    AUC = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "except ValueError:\n",
    "    pass\n",
    "print(f'\\n time {time.time()-start_time}')\n",
    "print(f'Logistic Regression by Grid Search: accuracy {accuracy}, precision {precision}, recall {recall}, f-score {F1}, AUC {AUC}')\n",
    "#Logistic Regression Random Search {'tol': 0.01, 'penalty': 'l2', 'C': 10}\n",
    "start_time = time.time()\n",
    "model = sklearn.linear_model.LogisticRegression(C=10, penalty='l2', tol=0.01, max_iter=750)\n",
    "model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "F1 = f1_score(y_test, y_pred)\n",
    "try:\n",
    "    AUC = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "except ValueError:\n",
    "    pass    \n",
    "print(f'\\n time {time.time()-start_time}')\n",
    "print(f'Logistic Regression by Random Search: accuracy {accuracy}, precision {precision}, recall {recall}, f-score {F1}, AUC {AUC}')\n",
    "#RF Random Search {'n_estimators': 25, 'min_samples_split': 2, 'max_features': 'auto', 'max_depth': None}\n",
    "start_time = time.time()\n",
    "random_forest = RandomForestClassifier(n_estimators=25,min_samples_split=2,max_features=\"auto\")\n",
    "random_forest.fit(X_train_oversampled, y_train_oversampled )\n",
    "y_pred = random_forest.predict(X.iloc[test_idx, :])\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = random_forest.score(X.iloc[test_idx, :], y.iloc[test_idx, :])\n",
    "#Calculate precision\n",
    "precision = precision_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate recall\n",
    "recall = recall_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate f-measure\n",
    "F1 = f1_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate AUC\n",
    "AUC = roc_auc_score(y.iloc[test_idx, :], model.predict_proba(X.iloc[test_idx,:])[:,1])\n",
    "print(f'\\n time {time.time()-start_time}')\n",
    "print(f'Random Forest by Random Search: accuracy {accuracy}, precision {precision}, recall {recall}, f-score {F1}, AUC {AUC}')\n",
    "#RF Grid Search {'max_depth': 4, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 250}\n",
    "start_time = time.time()\n",
    "model = RandomForestClassifier(n_estimators=250, min_samples_split=2, max_features=\"auto\",max_depth=4)\n",
    "random_forest.fit(X_train_oversampled, y_train_oversampled )\n",
    "y_pred = random_forest.predict(X.iloc[test_idx, :])\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = random_forest.score(X.iloc[test_idx, :], y.iloc[test_idx, :])\n",
    "#Calculate precision\n",
    "precision = precision_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate recall\n",
    "recall = recall_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate f-measure\n",
    "F1 = f1_score(y.iloc[test_idx, :], y_pred)\n",
    "#Calculate AUC\n",
    "AUC = roc_auc_score(y.iloc[test_idx, :], model.predict_proba(X.iloc[test_idx,:])[:,1])\n",
    "print(f'\\n time {time.time()-start_time}')\n",
    "print(f'Random Forest by Grid Search: accuracy {accuracy}, precision {precision}, recall {recall}, f-score {F1}, AUC {AUC}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "struggling to get XGB to work, it was running for 10+ hours here before it came up with that message, not great Bob! Random Forest works better than Logit in all the previous cases, not sure why that would change now that we have optimized the hyperparameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  take-away message \n",
    "\n",
    "Grid Search is noticeably slower than Random Search. Results do not provide better information gain on this data set from longer wait times for hyperparameter value extraction. Thus, in terms of performance optimization I would recommend Random Search over Grid, as they are evaluating over the same information space of parameters to select from. \n",
    "\n",
    "Random Forests & XGB perform similarly according to AUC, but XGB has better Precision & Recall, but this might also be because of overfitting. GBM's are harder to tune than RF's, and because this is a very noisy data set from its class disproportion, using the sampling techniques that we used could cause information misrepresentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
